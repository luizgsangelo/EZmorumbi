{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"ENTRADASEBZMORUMBI2025 - Entradas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e primeiras colunas deletadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"ENTRADASEBZMORUMBI2025 - Entradas.csv\")\n",
    "df = df.dropna(subset=(\"Colaborador\"))\n",
    "df.drop(columns=[\"Unnamed: 48\",\"Unnamed: 49\"],inplace=True) \n",
    "df.rename(columns={' ': \"data\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo classe e funções de limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "passage: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "class data_cleaning(pd.DataFrame):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def to_date(self, date_column: str) -> \"data_cleaning\":\n",
    "        \"\"\"\n",
    "        Converts a column to datetime format.\n",
    "\n",
    "        Args:\n",
    "            date_column (str): The name of the column to convert.\n",
    "\n",
    "        Returns:\n",
    "            data_cleaning: The updated DataFrame with the column converted to datetime.\n",
    "        \"\"\"\n",
    "        self[date_column] = pd.to_datetime(self[date_column], format=\"%d/%m/%Y\")\n",
    "        return self\n",
    "        \n",
    "    def normalize_dollar(self, dollar_column: str) -> \"data_cleaning\":\n",
    "        \"\"\"\n",
    "        Normalizes a column with dollar values by removing currency symbols and converting to float.\n",
    "\n",
    "        Args:\n",
    "            dollar_column (str): The name of the column to normalize.\n",
    "\n",
    "        Returns:\n",
    "            data_cleaning: The updated DataFrame with the column normalized.\n",
    "        \"\"\"\n",
    "        if dollar_column in self.columns:\n",
    "            self[dollar_column] = self[dollar_column].apply(\n",
    "                lambda x: x.replace(\"R$ \", \"\").replace(\",\", \".\").replace(\" \", \"\").replace(\"0.0.0\", \"0\") if isinstance(x, str) else x\n",
    "            )\n",
    "            self[dollar_column] = self[dollar_column].astype(float)\n",
    "        return self\n",
    "    \n",
    "    def to_boolean(self, column: str) -> \"data_cleaning\":\n",
    "        \"\"\"\n",
    "        Converts a column with \"SIM\"/\"NÃO\" values to boolean.\n",
    "\n",
    "        Args:\n",
    "            column (str): The name of the column to convert.\n",
    "\n",
    "        Returns:\n",
    "            data_cleaning: The updated DataFrame with the column converted to boolean.\n",
    "        \"\"\"\n",
    "        if column in self.columns:\n",
    "            self[column] = self[column].map({\"NÃO\": False, \"SIM\": True}).astype(bool)\n",
    "        return self   \n",
    "    \n",
    "    def to_null(self, column: str) -> \"data_cleaning\":\n",
    "        \"\"\"\n",
    "        Replaces \"VAZIO\" values in a column with NaN.\n",
    "\n",
    "        Args:\n",
    "            column (str): The name of the column to process.\n",
    "\n",
    "        Returns:\n",
    "            data_cleaning: The updated DataFrame with \"VAZIO\" replaced by NaN.\n",
    "        \"\"\"\n",
    "        if column in self.columns:\n",
    "            self[column] = self[column].apply(lambda x: np.nan if x == \"VAZIO\" else x)\n",
    "        return self\n",
    "    \n",
    "    def rename_second_column(self) -> \"data_cleaning\":\n",
    "        \"\"\"\n",
    "        Renames the first four columns of the DataFrame to standardized names.\n",
    "\n",
    "        Returns:\n",
    "            data_cleaning: The updated DataFrame with renamed columns.\n",
    "        \"\"\"\n",
    "        if len(self.columns) > 1:\n",
    "            self.rename(columns={self.columns[0]: \"produto\"}, inplace=True)\n",
    "            self.rename(columns={self.columns[1]: \"vl_venda\"}, inplace=True)\n",
    "            self.rename(columns={self.columns[2]: \"compra\"}, inplace=True)\n",
    "            self.rename(columns={self.columns[3]: \"lucro\"}, inplace=True)\n",
    "        return self\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_its_own_dimension(base_dataframe: pd.DataFrame, key: str, value: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a new DataFrame with unique combinations of key and value columns.\n",
    "\n",
    "        Args:\n",
    "            base_dataframe (pd.DataFrame): The base DataFrame.\n",
    "            key (str): The column name to use as the key.\n",
    "            value (str): The column name to use as the value.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The new DataFrame with unique combinations.\n",
    "        \"\"\"\n",
    "        new_dataframe = base_dataframe[[\"ID\", key, value]].drop_duplicates()\n",
    "        new_dataframe[\"type\"] = key \n",
    "        new_dataframe = new_dataframe.rename(columns={key: \"produtos\", value: \"quantidade\"})\n",
    "\n",
    "        passage[key] = new_dataframe\n",
    "\n",
    "        combined_dataframe = pd.concat(passage.values(), ignore_index=True)\n",
    "\n",
    "        return combined_dataframe\n",
    "    \n",
    "class feature_engineering(data_cleaning):\n",
    "     \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "         \n",
    "    def index_values(self, column: str) -> \"feature_engineering\":\n",
    "        \"\"\"\n",
    "        Creates a mapping of unique values in a column to unique indices.\n",
    "\n",
    "        Args:\n",
    "            column (str): The column to index.\n",
    "\n",
    "        Returns:\n",
    "            feature_engineering: The updated DataFrame with an indexed column.\n",
    "        \"\"\"\n",
    "        unique_values = self[column].unique()\n",
    "        dicionario = {value: key for key, value in enumerate(unique_values)}\n",
    "        self[f\"id_{column}\"] = self[column].map(dicionario)\n",
    "        return self\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_cleaning(df)\n",
    "df = df.to_date(\"data\")\n",
    "\n",
    "colunas_valor = [col for col in df.columns if col.startswith(\"Valor\")] + [\"TaxaMaquina\",\"Total(S+P)\",\"Total(S+P)*T\",\"Total[(S+P)-LP]*T\",\"TotalS+LP-Col\",\"TotalColaborador\",\"Colaborador50%\"] + [col for col in df.columns if col.startswith(\"AuxValor\")] + [col for col in df.columns if col.startswith(\"AuxDesconto\")]\n",
    "for col in colunas_valor:\n",
    "    df = df.normalize_dollar(col)\n",
    "\n",
    "colunas_valor = [col for col in df.columns if col.startswith(\"AuxValor\")]\n",
    "for col in colunas_valor:\n",
    "    df = df.normalize_dollar(col)\n",
    "    \n",
    "df = df.to_boolean(\"ClienteNovo\")\n",
    "\n",
    "colunas = [\"Produto\",\"Doces\",\"Salgados\",\"Bebidas\"]\n",
    "for col in colunas:\n",
    "    df = df.to_null(col)\n",
    "    \n",
    "combine_columns = {\n",
    "    \"Produto\": \"QuantidadeProduto\",\n",
    "    \"Doces\": \"QuantidadeDoces\",\n",
    "    \"Salgados\": \"QuantidadeSalgados\",\n",
    "    \"Bebidas\": \"QuantidadeBebidas\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando dimensão de produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "produtos = pd.read_csv(r\"c:\\Users\\luiz\\Documents\\GitHub\\EZmorumbi\\Data Cleaning\\ENTRADASEBZMORUMBI2025 - Produtos.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpeza produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_servico = produtos[[\"SERVIÇO\",\"VALOR DO SERVIÇO\"]]\n",
    "dim_produto = produtos[[\"PRODUTO\",\"VALOR DE VENDA\",\"VALOR DE COMPRA\",\"LUCRO\"]]\n",
    "dim_doce = produtos[[\"DOCE\",\"VALOR DE VENDA.1\",\"VALOR DE COMPRA.1\",\"LUCRO.1\"]]\n",
    "dim_salgado = produtos[[\"SALGADO\",\"VALOR DE VENDA.2\",\"VALOR DE COMPRA.2\",\"LUCRO.2\"]]\n",
    "dim_bebida = produtos[[\"BEBIDA\",\"VALOR DE VENDA.3\",\"VALOR DE COMPRA.3\",\"LUCRO.3\"]]\n",
    "dim_funcionario = produtos[[\"FUNCIONARIO\",\"PORCENTAGEM\"]]\n",
    "dim_taxa = produtos[[\"FUNCAO\",\"TAXA\"]]\n",
    "\n",
    "dim_servico[\"tipo\"] = \"servico\"\n",
    "dim_doce[\"tipo\"] = \"doce\"\n",
    "dim_salgado[\"tipo\"] = \"salgado\"\n",
    "dim_bebida[\"tipo\"] = \"bebida\"\n",
    "dim_funcionario[\"tipo\"] = \"funcionario\"\n",
    "dim_taxa[\"tipo\"] = \"taxa\"\n",
    "\n",
    "dataframes = [dim_servico,dim_produto,dim_doce,dim_salgado,dim_bebida,dim_funcionario,dim_taxa]\n",
    "\n",
    "dim_servico = data_cleaning(dim_servico)\n",
    "dim_produto = data_cleaning(dim_produto)\n",
    "dim_doce = data_cleaning(dim_doce)\n",
    "dim_salgado = data_cleaning(dim_salgado)\n",
    "\n",
    "dim_produto.rename_second_column()\n",
    "dim_doce.rename_second_column()\n",
    "dim_salgado.rename_second_column()\n",
    "dim_bebida.rename_second_column()\n",
    "\n",
    "for data in dataframes:\n",
    "    data.dropna(inplace=True)\n",
    "    \n",
    "dim_servico.rename(columns={\n",
    "    \"SERVIÇO\" : \"servico\",\n",
    "    \"VALOR DO SERVIÇO\" : \"vl_venda\"\n",
    "})\n",
    "\n",
    "dim_produto = dim_produto.normalize_dollar(\"lucro\")\n",
    "dim_doce = dim_doce.normalize_dollar(\"lucro\")\n",
    "dim_salgado = dim_salgado.normalize_dollar(\"lucro\")\n",
    "dim_bebida = dim_bebida.normalize_dollar(\"lucro\")\n",
    "dim_produto = dim_produto.normalize_dollar(\"vl_venda\")\n",
    "dim_doce = dim_doce.normalize_dollar(\"vl_venda\")\n",
    "dim_salgado = dim_salgado.normalize_dollar(\"vl_venda\")\n",
    "dim_bebida = dim_bebida.normalize_dollar(\"vl_venda\")\n",
    "dim_produto = dim_produto.normalize_dollar(\"compra\")\n",
    "dim_doce = dim_doce.normalize_dollar(\"compra\")\n",
    "dim_salgado = dim_salgado.normalize_dollar(\"compra\")\n",
    "dim_bebida = dim_bebida.normalize_dollar(\"compra\")\n",
    "\n",
    "def to_string(dataframe,coluna):\n",
    "    dataframe[coluna] = dataframe[coluna].astype(str)\n",
    "    return dataframe[coluna].apply(lambda x: type(x)).value_counts()\n",
    "\n",
    "to_string(dim_bebida,\"produto\")\n",
    "to_string(dim_produto,\"produto\")\n",
    "dim_produto = dim_produto[dim_produto[\"produto\"] != \"VAZIO\"]\n",
    "\n",
    "dataframes = [dim_bebida, dim_doce, dim_salgado]\n",
    "for df in dataframes:\n",
    "    df.dropna(subset=[\"vl_venda\"],inplace=True)\n",
    "    \n",
    "dim_produto_2 = pd.concat([dim_bebida, dim_doce, dim_salgado])\n",
    "\n",
    "dim_p_b = dim_produto.merge(dim_produto_2, on=\"produto\", how=\"left\", suffixes=(\"\", \"n_\"))\n",
    "dim_p_b.drop(columns=[\"vl_vendan_\",\"compran_\",\"lucron_\"],inplace=True)\n",
    "dim_p_b.dropna(subset=\"vl_venda\",inplace=True)\n",
    "dim_p_b[\"tipo\"] = dim_p_b[\"tipo\"].apply(lambda x: \"barbearia\" if pd.isna(x) else x)\n",
    "dim_p_b.drop_duplicates(subset=[\"produto\"],inplace=True)\n",
    "dim_p_b = feature_engineering(dim_p_b)\n",
    "dim_p_b = dim_p_b.index_values(\"produto\")\n",
    "produto_map = dim_p_b.set_index(\"produto\")[\"id_produto\"].to_dict()\n",
    "\n",
    "passage: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "for key, value in combine_columns.items():\n",
    "    result_dataframe = data_cleaning.to_its_own_dimension(df, key, value)\n",
    "\n",
    "result_dataframe.dropna(subset=\"produtos\", inplace=True)\n",
    "result_dataframe = result_dataframe.assign(produtos=result_dataframe[\"produtos\"].str.split(\",\")).explode(\"produtos\")\n",
    "result_dataframe[\"quantidade\"] = 1\n",
    "result_dataframe[\"produtos\"].unique()\n",
    "fato_produtos = result_dataframe\n",
    "fato_produtos.rename(columns={\"ID\": \"id_servico\"}, inplace=True)\n",
    "fato_produtos[\"id_servico\"] = fato_produtos[\"id_servico\"].astype(int)\n",
    "fato_produtos = fato_produtos.merge(dim_p_b, left_on=\"produtos\", right_on=\"produto\", how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando tabela Fato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_fato = new_df[['data', 'ID', 'Colaborador', 'Cliente', 'Servico', 'ValordoServico',\n",
    "       'ClienteNovo', 'Local', 'Produto', 'QuantidadeProduto',\n",
    "       'ValorTotaldosProduto', 'Doces',\n",
    "       'QuantidadeDoces', 'ValorTotaldosDoces', 'Salgados', 'QuantidadeSalgados',\n",
    "       'Bebidas', 'QuantidadeBebidas',\n",
    "       'ValorTotaldasBebidas', 'FormadePagamento', 'TaxaMaquina', 'Total(S+P)',\n",
    "       'Total(S+P)*T', 'Total[(S+P)-LP]*T', 'TotalS+LP-Col',\n",
    "       'TotalColaborador', 'Colaborador50%']]\n",
    "\n",
    "tabela_fato = tabela_fato.rename(columns={\n",
    "    'data': 'data',\n",
    "    'ID': 'id',\n",
    "    'Colaborador': 'colaborador',\n",
    "    'Cliente': 'cliente',\n",
    "    'Servico': 'servico',\n",
    "    'ValordoServico': 'vl_servico',\n",
    "    'ClienteNovo': 'cliente_novo',\n",
    "    'Local': 'local',  \n",
    "    'Produto': 'produto',\n",
    "    'QuantidadeProduto': 'qtd_produto',\n",
    "    'ValorTotaldosProduto': 'vl_total_produto',\n",
    "    'Doces': 'doce',\n",
    "    'QuantidadeDoces': 'qtd_doce',\n",
    "    'ValorTotaldosDoces': 'vl_total_doces',\n",
    "    'Salgados': 'salgado',  \n",
    "    'QuantidadeSalgados': 'qtd_salgado',\n",
    "    'ValorTotaldosSalgados': 'vl_total_salgado',\n",
    "    'Bebidas': 'bebida',  \n",
    "    'QuantidadeBebidas': 'qtd_bebida',\n",
    "    'ValorTotaldasBebidas': 'vl_total_bebida',\n",
    "    'FormadePagamento': 'forma_de_pagamento',\n",
    "    'TaxaMaquina': 'tx_maquina',\n",
    "    'Total(S+P)': 'total_sp',\n",
    "    'Total(S+P)*T': 'total_spt',\n",
    "    'Total[(S+P)-LP]*T': 'total_splt',\n",
    "    'TotalS+LP-Col': 'total_slp_col',\n",
    "    'TotalColaborador': 'total_colaborador',\n",
    "    'Colaborador50%': 'colaborador_50'\n",
    "    'local': 'fidelizado'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação da tabela "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(cursor):\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS tabela_fato (\n",
    "            data DATETIME,\n",
    "            id DOUBLE,\n",
    "            colaborador TEXT,\n",
    "            cliente TEXT,\n",
    "            servico TEXT,\n",
    "            vl_servico DOUBLE,\n",
    "            cliente_novo BOOLEAN,\n",
    "            fidelizado TEXT,\n",
    "            produto TEXT,\n",
    "            qtd_produto TEXT,\n",
    "            vl_total_produto DOUBLE,\n",
    "            doce TEXT,\n",
    "            qtd_doce DOUBLE,\n",
    "            vl_total_doces DOUBLE,\n",
    "            salgado TEXT,\n",
    "            qtd_salgado DOUBLE,\n",
    "            bebida TEXT,\n",
    "            qtd_bebida TEXT,\n",
    "            vl_total_bebida DOUBLE,\n",
    "            forma_de_pagamento TEXT,\n",
    "            tx_maquina DOUBLE,\n",
    "            total_sp DOUBLE,\n",
    "            total_spt DOUBLE,\n",
    "            total_splt DOUBLE,\n",
    "            total_slp_col DOUBLE,\n",
    "            total_colaborador DOUBLE,\n",
    "            colaborador_50 DOUBLE\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "def insert_data(cursor, df):\n",
    "    for _, row in df.iterrows():\n",
    "        cursor.execute('''\n",
    "            INSERT INTO tabela_fato VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        ''', tuple(row))\n",
    "\n",
    "def main(df):\n",
    "    conn = mysql.connector.connect(\n",
    "        host='database-atinova.ct6oomqu6y49.sa-east-1.rds.amazonaws.com',\n",
    "        user='integrantes',\n",
    "        password='grupoPI2025',\n",
    "        database='barbearia',  # Substituir pelo nome correto do banco de dados\n",
    "        port=3306\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    create_table(cursor)\n",
    "    \n",
    "    df.fillna('', inplace=True)  # Substituir NaN por strings vazias\n",
    "    insert_data(cursor, df)\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# Chame a função passando seu DataFrame diretamente\n",
    "main(tabela_fato)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Univesp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
