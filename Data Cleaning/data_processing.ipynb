{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"ENTRADASEBZMORUMBI2025 - Entradas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura e primeiras colunas deletadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"ENTRADASEBZMORUMBI2025 - Entradas.csv\")\n",
    "df = df.dropna(subset=(\"Colaborador\"))\n",
    "df.drop(columns=[\"Unnamed: 48\", \"Unnamed: 49\"], inplace=True)\n",
    "df.rename(columns={\" \": \"data\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo classe e funções de limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "passage: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "\n",
    "class data_cleaning(pd.DataFrame):\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def to_date(self, date_column: str) -> \"data_cleaning\":\n",
    "        \"\"\"\n",
    "        Converts a column to datetime format.\n",
    "\n",
    "        Args:\n",
    "            date_column (str): The name of the column to convert.\n",
    "\n",
    "        Returns:\n",
    "            data_cleaning: The updated DataFrame with the column converted to datetime.\n",
    "        \"\"\"\n",
    "        self[date_column] = pd.to_datetime(self[date_column], format=\"%d/%m/%Y\")\n",
    "        return self\n",
    "\n",
    "    def normalize_dollar(self, dollar_column: str) -> \"data_cleaning\":\n",
    "        \"\"\"\n",
    "        Normalizes a column with dollar values by removing currency symbols and converting to float.\n",
    "\n",
    "        Args:\n",
    "            dollar_column (str): The name of the column to normalize.\n",
    "\n",
    "        Returns:\n",
    "            data_cleaning: The updated DataFrame with the column normalized.\n",
    "        \"\"\"\n",
    "        if dollar_column in self.columns:\n",
    "            self[dollar_column] = self[dollar_column].apply(\n",
    "                lambda x: (\n",
    "                    x.replace(\"R$ \", \"\")\n",
    "                    .replace(\",\", \".\")\n",
    "                    .replace(\" \", \"\")\n",
    "                    .replace(\"0.0.0\", \"0\")\n",
    "                    if isinstance(x, str)\n",
    "                    else x\n",
    "                )\n",
    "            )\n",
    "            self[dollar_column] = self[dollar_column].astype(float)\n",
    "        return self\n",
    "\n",
    "    def to_boolean(self, column: str) -> \"data_cleaning\":\n",
    "        \"\"\"\n",
    "        Converts a column with \"SIM\"/\"NÃO\" values to boolean.\n",
    "\n",
    "        Args:\n",
    "            column (str): The name of the column to convert.\n",
    "\n",
    "        Returns:\n",
    "            data_cleaning: The updated DataFrame with the column converted to boolean.\n",
    "        \"\"\"\n",
    "        if column in self.columns:\n",
    "            self[column] = self[column].map({\"NÃO\": False, \"SIM\": True}).astype(bool)\n",
    "        return self\n",
    "\n",
    "    def to_null(self, column: str) -> \"data_cleaning\":\n",
    "        \"\"\"\n",
    "        Replaces \"VAZIO\" values in a column with NaN.\n",
    "\n",
    "        Args:\n",
    "            column (str): The name of the column to process.\n",
    "\n",
    "        Returns:\n",
    "            data_cleaning: The updated DataFrame with \"VAZIO\" replaced by NaN.\n",
    "        \"\"\"\n",
    "        if column in self.columns:\n",
    "            self[column] = self[column].apply(lambda x: np.nan if x == \"VAZIO\" else x)\n",
    "        return self\n",
    "\n",
    "    def rename_second_column(self) -> \"data_cleaning\":\n",
    "        \"\"\"\n",
    "        Renames the first four columns of the DataFrame to standardized names.\n",
    "\n",
    "        Returns:\n",
    "            data_cleaning: The updated DataFrame with renamed columns.\n",
    "        \"\"\"\n",
    "        if len(self.columns) > 1:\n",
    "            self.rename(columns={self.columns[0]: \"produto\"}, inplace=True)\n",
    "            self.rename(columns={self.columns[1]: \"vl_venda\"}, inplace=True)\n",
    "            self.rename(columns={self.columns[2]: \"compra\"}, inplace=True)\n",
    "            self.rename(columns={self.columns[3]: \"lucro\"}, inplace=True)\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def to_its_own_dimension(\n",
    "        base_dataframe: pd.DataFrame, key: str, value: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a new DataFrame with unique combinations of key and value columns.\n",
    "\n",
    "        Args:\n",
    "            base_dataframe (pd.DataFrame): The base DataFrame.\n",
    "            key (str): The column name to use as the key.\n",
    "            value (str): The column name to use as the value.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: The new DataFrame with unique combinations.\n",
    "        \"\"\"\n",
    "        new_dataframe = base_dataframe[[\"ID\", key, value]].drop_duplicates()\n",
    "        new_dataframe[\"type\"] = key\n",
    "        new_dataframe = new_dataframe.rename(\n",
    "            columns={key: \"produtos\", value: \"quantidade\"}\n",
    "        )\n",
    "\n",
    "        passage[key] = new_dataframe\n",
    "\n",
    "        combined_dataframe = pd.concat(passage.values(), ignore_index=True)\n",
    "\n",
    "        return combined_dataframe\n",
    "\n",
    "\n",
    "class feature_engineering(data_cleaning):\n",
    "\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def index_values(self, column: str) -> \"feature_engineering\":\n",
    "        \"\"\"\n",
    "        Creates a mapping of unique values in a column to unique indices.\n",
    "\n",
    "        Args:\n",
    "            column (str): The column to index.\n",
    "\n",
    "        Returns:\n",
    "            feature_engineering: The updated DataFrame with an indexed column.\n",
    "        \"\"\"\n",
    "        unique_values = self[column].unique()\n",
    "        dicionario = {value: key for key, value in enumerate(unique_values)}\n",
    "        self[f\"id_{column}\"] = self[column].map(dicionario)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpando dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_cleaning(df)\n",
    "df = df.to_date(\"data\")\n",
    "\n",
    "colunas_valor = (\n",
    "    [col for col in df.columns if col.startswith(\"Valor\")]\n",
    "    + [\n",
    "        \"TaxaMaquina\",\n",
    "        \"Total(S+P)\",\n",
    "        \"Total(S+P)*T\",\n",
    "        \"Total[(S+P)-LP]*T\",\n",
    "        \"TotalS+LP-Col\",\n",
    "        \"TotalColaborador\",\n",
    "        \"Colaborador50%\",\n",
    "    ]\n",
    "    + [col for col in df.columns if col.startswith(\"AuxValor\")]\n",
    "    + [col for col in df.columns if col.startswith(\"AuxDesconto\")]\n",
    ")\n",
    "for col in colunas_valor:\n",
    "    df = df.normalize_dollar(col)\n",
    "\n",
    "colunas_valor = [col for col in df.columns if col.startswith(\"AuxValor\")]\n",
    "for col in colunas_valor:\n",
    "    df = df.normalize_dollar(col)\n",
    "\n",
    "df = df.to_boolean(\"ClienteNovo\")\n",
    "\n",
    "colunas = [\"Produto\", \"Doces\", \"Salgados\", \"Bebidas\"]\n",
    "for col in colunas:\n",
    "    df = df.to_null(col)\n",
    "\n",
    "combine_columns = {\n",
    "    \"Produto\": \"QuantidadeProduto\",\n",
    "    \"Doces\": \"QuantidadeDoces\",\n",
    "    \"Salgados\": \"QuantidadeSalgados\",\n",
    "    \"Bebidas\": \"QuantidadeBebidas\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.data_cleaning'>\n",
      "Index: 812 entries, 0 to 811\n",
      "Data columns (total 51 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   data                           812 non-null    datetime64[ns]\n",
      " 1   ID                             812 non-null    float64       \n",
      " 2   Colaborador                    812 non-null    object        \n",
      " 3   Cliente                        812 non-null    object        \n",
      " 4   Servico                        812 non-null    object        \n",
      " 5   ValordoServico                 812 non-null    float64       \n",
      " 6   ClienteNovo                    812 non-null    bool          \n",
      " 7   Local                          805 non-null    object        \n",
      " 8   Produto                        21 non-null     object        \n",
      " 9   QuantidadeProduto              812 non-null    object        \n",
      " 10  ValorTotaldosProduto           812 non-null    float64       \n",
      " 11  AuxValorTotalCompraProdutos    812 non-null    float64       \n",
      " 12  AuxDescontoProdutos            812 non-null    float64       \n",
      " 13  PorcentagemProdutoColaborador  812 non-null    object        \n",
      " 14  Doces                          31 non-null     object        \n",
      " 15  QuantidadeDoces                812 non-null    float64       \n",
      " 16  ValorTotaldosDoces             812 non-null    float64       \n",
      " 17  AuxValorTotalCompraDoces       812 non-null    float64       \n",
      " 18  AuxDescontoDoces               812 non-null    float64       \n",
      " 19  Salgados                       16 non-null     object        \n",
      " 20  QuantidadeSalgados             812 non-null    float64       \n",
      " 21  ValorTotaldosSalgados          812 non-null    float64       \n",
      " 22  AuxValorTotalComprasSalgados   812 non-null    float64       \n",
      " 23  AuxDescontoSalgados            812 non-null    float64       \n",
      " 24  Bebidas                        40 non-null     object        \n",
      " 25  QuantidadeBebidas              812 non-null    object        \n",
      " 26  ValorTotaldasBebidas           812 non-null    float64       \n",
      " 27  AuxValorTotalComprasBebidas    812 non-null    float64       \n",
      " 28  AuxDescontoBebidas             812 non-null    float64       \n",
      " 29  FormadePagamento               812 non-null    object        \n",
      " 30  TaxaMaquina                    812 non-null    float64       \n",
      " 31  Total(S+P)                     812 non-null    float64       \n",
      " 32  Total(S+P)*T                   812 non-null    float64       \n",
      " 33  Total[(S+P)-LP]*T              812 non-null    float64       \n",
      " 34  TotalS+LP-Col                  812 non-null    float64       \n",
      " 35  TotalColaborador               812 non-null    float64       \n",
      " 36  Colaborador50%                 812 non-null    float64       \n",
      " 37  AuxDadosProdutos               699 non-null    object        \n",
      " 38  AuxDatasProdutos               83 non-null     object        \n",
      " 39  Unnamed: 39                    101 non-null    object        \n",
      " 40  DATA                           101 non-null    object        \n",
      " 41  Unnamed: 41                    83 non-null     object        \n",
      " 42  PRODUTOS                       101 non-null    object        \n",
      " 43  AuxQuantidadeProdutos          96 non-null     object        \n",
      " 44  AuxDescontoProdutos.1          96 non-null     float64       \n",
      " 45  AuxTaxas                       761 non-null    object        \n",
      " 46  TaxaFinal                      96 non-null     object        \n",
      " 47  ID.1                           10 non-null     object        \n",
      " 48  AuxDescontoProdutos.2          19 non-null     float64       \n",
      " 49  AuxTaxas.1                     192 non-null    object        \n",
      " 50  TaxaFinal.1                    23 non-null     object        \n",
      "dtypes: bool(1), datetime64[ns](1), float64(25), object(24)\n",
      "memory usage: 324.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando dimensão de produto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "produtos = pd.read_csv(\n",
    "    r\"c:\\Users\\luiz\\Documents\\GitHub\\EZmorumbi\\Data Cleaning\\ENTRADASEBZMORUMBI2025 - Produtos.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luiz\\AppData\\Local\\Temp\\ipykernel_21280\\1467787261.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dim_servico[\"tipo\"] = \"servico\"\n",
      "C:\\Users\\luiz\\AppData\\Local\\Temp\\ipykernel_21280\\1467787261.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dim_doce[\"tipo\"] = \"doce\"\n",
      "C:\\Users\\luiz\\AppData\\Local\\Temp\\ipykernel_21280\\1467787261.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dim_salgado[\"tipo\"] = \"salgado\"\n",
      "C:\\Users\\luiz\\AppData\\Local\\Temp\\ipykernel_21280\\1467787261.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dim_bebida[\"tipo\"] = \"bebida\"\n",
      "C:\\Users\\luiz\\AppData\\Local\\Temp\\ipykernel_21280\\1467787261.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dim_funcionario[\"tipo\"] = \"funcionario\"\n",
      "C:\\Users\\luiz\\AppData\\Local\\Temp\\ipykernel_21280\\1467787261.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dim_taxa[\"tipo\"] = \"taxa\"\n",
      "C:\\Users\\luiz\\AppData\\Local\\Temp\\ipykernel_21280\\1467787261.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(inplace=True)\n",
      "C:\\Users\\luiz\\AppData\\Local\\Temp\\ipykernel_21280\\1467787261.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(inplace=True)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['ID', 'Produto', 'QuantidadeProduto'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m passage: Dict[\u001b[38;5;28mstr\u001b[39m, pd\u001b[38;5;241m.\u001b[39mDataFrame] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m combine_columns\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 85\u001b[0m     result_dataframe \u001b[38;5;241m=\u001b[39m data_cleaning\u001b[38;5;241m.\u001b[39mto_its_own_dimension(df, key, value)\n\u001b[0;32m     87\u001b[0m result_dataframe\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprodutos\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     88\u001b[0m result_dataframe \u001b[38;5;241m=\u001b[39m result_dataframe\u001b[38;5;241m.\u001b[39massign(\n\u001b[0;32m     89\u001b[0m     produtos\u001b[38;5;241m=\u001b[39mresult_dataframe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprodutos\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m )\u001b[38;5;241m.\u001b[39mexplode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprodutos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 107\u001b[0m, in \u001b[0;36mdata_cleaning.to_its_own_dimension\u001b[1;34m(base_dataframe, key, value)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_its_own_dimension\u001b[39m(\n\u001b[0;32m     94\u001b[0m     base_dataframe: pd\u001b[38;5;241m.\u001b[39mDataFrame, key: \u001b[38;5;28mstr\u001b[39m, value: \u001b[38;5;28mstr\u001b[39m\n\u001b[0;32m     95\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[0;32m     96\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    Creates a new DataFrame with unique combinations of key and value columns.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m        pd.DataFrame: The new DataFrame with unique combinations.\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m     new_dataframe \u001b[38;5;241m=\u001b[39m base_dataframe[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m, key, value]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n\u001b[0;32m    108\u001b[0m     new_dataframe[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m key\n\u001b[0;32m    109\u001b[0m     new_dataframe \u001b[38;5;241m=\u001b[39m new_dataframe\u001b[38;5;241m.\u001b[39mrename(\n\u001b[0;32m    110\u001b[0m         columns\u001b[38;5;241m=\u001b[39m{key: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprodutos\u001b[39m\u001b[38;5;124m\"\u001b[39m, value: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantidade\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    111\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\luiz\\anaconda3\\envs\\Univesp\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\luiz\\anaconda3\\envs\\Univesp\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\luiz\\anaconda3\\envs\\Univesp\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['ID', 'Produto', 'QuantidadeProduto'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "dim_servico = produtos[[\"SERVIÇO\", \"VALOR DO SERVIÇO\"]]\n",
    "dim_produto = produtos[[\"PRODUTO\", \"VALOR DE VENDA\", \"VALOR DE COMPRA\", \"LUCRO\"]]\n",
    "dim_doce = produtos[[\"DOCE\", \"VALOR DE VENDA.1\", \"VALOR DE COMPRA.1\", \"LUCRO.1\"]]\n",
    "dim_salgado = produtos[[\"SALGADO\", \"VALOR DE VENDA.2\", \"VALOR DE COMPRA.2\", \"LUCRO.2\"]]\n",
    "dim_bebida = produtos[[\"BEBIDA\", \"VALOR DE VENDA.3\", \"VALOR DE COMPRA.3\", \"LUCRO.3\"]]\n",
    "dim_funcionario = produtos[[\"FUNCIONARIO\", \"PORCENTAGEM\"]]\n",
    "dim_taxa = produtos[[\"FUNCAO\", \"TAXA\"]]\n",
    "\n",
    "dim_servico[\"tipo\"] = \"servico\"\n",
    "dim_doce[\"tipo\"] = \"doce\"\n",
    "dim_salgado[\"tipo\"] = \"salgado\"\n",
    "dim_bebida[\"tipo\"] = \"bebida\"\n",
    "dim_funcionario[\"tipo\"] = \"funcionario\"\n",
    "dim_taxa[\"tipo\"] = \"taxa\"\n",
    "\n",
    "dataframes = [\n",
    "    dim_servico,\n",
    "    dim_produto,\n",
    "    dim_doce,\n",
    "    dim_salgado,\n",
    "    dim_bebida,\n",
    "    dim_funcionario,\n",
    "    dim_taxa,\n",
    "]\n",
    "\n",
    "dim_servico = data_cleaning(dim_servico)\n",
    "dim_produto = data_cleaning(dim_produto)\n",
    "dim_doce = data_cleaning(dim_doce)\n",
    "dim_salgado = data_cleaning(dim_salgado)\n",
    "dim_bebida = data_cleaning(dim_bebida)\n",
    "\n",
    "dim_produto.rename_second_column()\n",
    "dim_doce.rename_second_column()\n",
    "dim_salgado.rename_second_column()\n",
    "dim_bebida.rename_second_column()\n",
    "\n",
    "for data in dataframes:\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "dim_servico.rename(columns={\"SERVIÇO\": \"servico\", \"VALOR DO SERVIÇO\": \"vl_venda\"})\n",
    "\n",
    "dim_produto = dim_produto.normalize_dollar(\"lucro\")\n",
    "dim_doce = dim_doce.normalize_dollar(\"lucro\")\n",
    "dim_salgado = dim_salgado.normalize_dollar(\"lucro\")\n",
    "dim_bebida = dim_bebida.normalize_dollar(\"lucro\")\n",
    "dim_produto = dim_produto.normalize_dollar(\"vl_venda\")\n",
    "dim_doce = dim_doce.normalize_dollar(\"vl_venda\")\n",
    "dim_salgado = dim_salgado.normalize_dollar(\"vl_venda\")\n",
    "dim_bebida = dim_bebida.normalize_dollar(\"vl_venda\")\n",
    "dim_produto = dim_produto.normalize_dollar(\"compra\")\n",
    "dim_doce = dim_doce.normalize_dollar(\"compra\")\n",
    "dim_salgado = dim_salgado.normalize_dollar(\"compra\")\n",
    "dim_bebida = dim_bebida.normalize_dollar(\"compra\")\n",
    "\n",
    "\n",
    "def to_string(dataframe, coluna):\n",
    "    dataframe[coluna] = dataframe[coluna].astype(str)\n",
    "    return dataframe[coluna].apply(lambda x: type(x)).value_counts()\n",
    "\n",
    "\n",
    "to_string(dim_bebida, \"produto\")\n",
    "to_string(dim_produto, \"produto\")\n",
    "dim_produto = dim_produto[dim_produto[\"produto\"] != \"VAZIO\"]\n",
    "\n",
    "dataframes = [dim_bebida, dim_doce, dim_salgado]\n",
    "for df in dataframes:\n",
    "    df.dropna(subset=[\"vl_venda\"], inplace=True)\n",
    "\n",
    "dim_produto_2 = pd.concat([dim_bebida, dim_doce, dim_salgado])\n",
    "\n",
    "dim_p_b = dim_produto.merge(\n",
    "    dim_produto_2, on=\"produto\", how=\"left\", suffixes=(\"\", \"n_\")\n",
    ")\n",
    "dim_p_b.drop(columns=[\"vl_vendan_\", \"compran_\", \"lucron_\"], inplace=True)\n",
    "dim_p_b.dropna(subset=\"vl_venda\", inplace=True)\n",
    "dim_p_b[\"tipo\"] = dim_p_b[\"tipo\"].apply(lambda x: \"barbearia\" if pd.isna(x) else x)\n",
    "dim_p_b.drop_duplicates(subset=[\"produto\"], inplace=True)\n",
    "dim_p_b = feature_engineering(dim_p_b)\n",
    "dim_p_b = dim_p_b.index_values(\"produto\")\n",
    "produto_map = dim_p_b.set_index(\"produto\")[\"id_produto\"].to_dict()\n",
    "\n",
    "passage: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "for key, value in combine_columns.items():\n",
    "    result_dataframe = data_cleaning.to_its_own_dimension(df, key, value)\n",
    "\n",
    "result_dataframe.dropna(subset=\"produtos\", inplace=True)\n",
    "result_dataframe = result_dataframe.assign(\n",
    "    produtos=result_dataframe[\"produtos\"].str.split(\",\")\n",
    ").explode(\"produtos\")\n",
    "result_dataframe[\"quantidade\"] = 1\n",
    "result_dataframe[\"produtos\"].unique()\n",
    "fato_produtos = result_dataframe\n",
    "fato_produtos.rename(columns={\"ID\": \"id_servico\"}, inplace=True)\n",
    "fato_produtos[\"id_servico\"] = fato_produtos[\"id_servico\"].astype(int)\n",
    "fato_produtos = fato_produtos.merge(\n",
    "    dim_p_b, left_on=\"produtos\", right_on=\"produto\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpeza produtos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando tabela Fato\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_fato = df[\n",
    "    [\n",
    "        \"data\",\n",
    "        \"ID\",\n",
    "        \"Colaborador\",\n",
    "        \"Cliente\",\n",
    "        \"Servico\",\n",
    "        \"ValordoServico\",\n",
    "        \"ClienteNovo\",\n",
    "        \"Local\",\n",
    "        \"Produto\",\n",
    "        \"QuantidadeProduto\",\n",
    "        \"ValorTotaldosProduto\",\n",
    "        \"Doces\",\n",
    "        \"QuantidadeDoces\",\n",
    "        \"ValorTotaldosDoces\",\n",
    "        \"Salgados\",\n",
    "        \"QuantidadeSalgados\",\n",
    "        \"Bebidas\",\n",
    "        \"QuantidadeBebidas\",\n",
    "        \"ValorTotaldasBebidas\",\n",
    "        \"FormadePagamento\",\n",
    "        \"TaxaMaquina\",\n",
    "        \"Total(S+P)\",\n",
    "        \"Total(S+P)*T\",\n",
    "        \"Total[(S+P)-LP]*T\",\n",
    "        \"TotalS+LP-Col\",\n",
    "        \"TotalColaborador\",\n",
    "        \"Colaborador50%\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "tabela_fato = tabela_fato.rename(\n",
    "    columns={\n",
    "        \"data\": \"data\",\n",
    "        \"ID\": \"id\",\n",
    "        \"Colaborador\": \"colaborador\",\n",
    "        \"Cliente\": \"cliente\",\n",
    "        \"Servico\": \"servico\",\n",
    "        \"ValordoServico\": \"vl_servico\",\n",
    "        \"ClienteNovo\": \"cliente_novo\",\n",
    "        \"Local\": \"fidelizado\",\n",
    "        \"Produto\": \"produto\",\n",
    "        \"QuantidadeProduto\": \"qtd_produto\",\n",
    "        \"ValorTotaldosProduto\": \"vl_total_produto\",\n",
    "        \"Doces\": \"doce\",\n",
    "        \"QuantidadeDoces\": \"qtd_doce\",\n",
    "        \"ValorTotaldosDoces\": \"vl_total_doces\",\n",
    "        \"Salgados\": \"salgado\",\n",
    "        \"QuantidadeSalgados\": \"qtd_salgado\",\n",
    "        \"ValorTotaldosSalgados\": \"vl_total_salgado\",\n",
    "        \"Bebidas\": \"bebida\",\n",
    "        \"QuantidadeBebidas\": \"qtd_bebida\",\n",
    "        \"ValorTotaldasBebidas\": \"vl_total_bebida\",\n",
    "        \"FormadePagamento\": \"forma_de_pagamento\",\n",
    "        \"TaxaMaquina\": \"tx_maquina\",\n",
    "        \"Total(S+P)\": \"total_sp\",\n",
    "        \"Total(S+P)*T\": \"total_spt\",\n",
    "        \"Total[(S+P)-LP]*T\": \"total_splt\",\n",
    "        \"TotalS+LP-Col\": \"total_slp_col\",\n",
    "        \"TotalColaborador\": \"total_colaborador\",\n",
    "        \"Colaborador50%\": \"colaborador_50\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação da tabela "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "\n",
    "def create_table(cursor):\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS tabela_fato (\n",
    "            data DATETIME,\n",
    "            id DOUBLE,\n",
    "            colaborador TEXT,\n",
    "            cliente TEXT,\n",
    "            servico TEXT,\n",
    "            vl_servico DOUBLE,\n",
    "            cliente_novo BOOLEAN,\n",
    "            fidelizado TEXT,\n",
    "            produto TEXT,\n",
    "            qtd_produto TEXT,\n",
    "            vl_total_produto DOUBLE,\n",
    "            doce TEXT,\n",
    "            qtd_doce DOUBLE,\n",
    "            vl_total_doces DOUBLE,\n",
    "            salgado TEXT,\n",
    "            qtd_salgado DOUBLE,\n",
    "            bebida TEXT,\n",
    "            qtd_bebida TEXT,\n",
    "            vl_total_bebida DOUBLE,\n",
    "            forma_de_pagamento TEXT,\n",
    "            tx_maquina DOUBLE,\n",
    "            total_sp DOUBLE,\n",
    "            total_spt DOUBLE,\n",
    "            total_splt DOUBLE,\n",
    "            total_slp_col DOUBLE,\n",
    "            total_colaborador DOUBLE,\n",
    "            colaborador_50 DOUBLE\n",
    "        )\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def insert_data(cursor, df):\n",
    "    for _, row in df.iterrows():\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO tabela_fato VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\",\n",
    "            tuple(row),\n",
    "        )\n",
    "\n",
    "\n",
    "def main(df):\n",
    "    conn = mysql.connector.connect(\n",
    "        host=\"database-atinova.ct6oomqu6y49.sa-east-1.rds.amazonaws.com\",\n",
    "        user=\"integrantes\",\n",
    "        password=\"grupoPI2025\",\n",
    "        database=\"barbearia\",  # Substituir pelo nome correto do banco de dados\n",
    "        port=3306,\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    create_table(cursor)\n",
    "\n",
    "    df.fillna(\"\", inplace=True)  # Substituir NaN por strings vazias\n",
    "    insert_data(cursor, df)\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "# Chame a função passando seu DataFrame diretamente\n",
    "main(tabela_fato)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Univesp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
